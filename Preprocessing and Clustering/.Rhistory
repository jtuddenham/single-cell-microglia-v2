?FindMarkers
library(Seurat)
sessionInfo()
setwd("../Documents/GitHub/")
setwd("single-cell-microglia-v2/")
list.files("Single Cell Data")
?rm
list.files("Single Cell Data")
for(folder in list.files("Single Cell Data/")){}
for(folder in list.files("Single Cell Data/")){
list.files(paste0("Single Cell Data/", folder))
}
for(folder in list.files("Single Cell Data/")){
print(list.files(paste0("Single Cell Data/", folder)))
}
for(folder in list.files("Single Cell Data/")){
folder_files <- (list.files(paste0("Single Cell Data/", folder)))
}
for(folder in list.files("Single Cell Data/")){
folder_files <- (list.files(paste0("Single Cell Data/", folder)))
}
?files.remove()
remove()
?remove()
folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")]
paste0("Single Cell Data/", folder, "/", folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")])
for(folder in list.files("Single Cell Data/")){
folder_files <- (list.files(paste0("Single Cell Data/", folder)))
files.remove(paste0("Single Cell Data/", folder, "/", folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")]))
}
for(folder in list.files("Single Cell Data/")){
folder_files <- (list.files(paste0("Single Cell Data/", folder)))
remove(paste0("Single Cell Data/", folder, "/", folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")]))
}
remove(... = paste0("Single Cell Data/", folder, "/", folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")]))
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
remove(... = paste0("Single Cell Data/", folder, "/", x))
})
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
files.remove(... = paste0("Single Cell Data/", folder, "/", x))
})
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
unlink(... = paste0("Single Cell Data/", folder, "/", x))
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
unlink(... = paste0("Single Cell Data/", folder, "/", x))
})
})
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
unlink(... = paste0("Single Cell Data/", folder, "/", x))
})
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
file.remove(... = paste0("Single Cell Data/", folder, "/", x))
})
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
file.remove(... = paste0("Single Cell Data/", folder, "/", x))
})
list.files("Single Cell Data/")
for(folder in list.files("Single Cell Data/")[-1]){
folder_files <- (list.files(paste0("Single Cell Data/", folder)))
sapply(folder_files[!(folder_files == "filtered_feature_bc_matrix.h5")], function(x) {
file.remove(... = paste0("Single Cell Data/", folder, "/", x))
})
}
setwd("Preprocessing and Clustering/")
source("clustering_diffex_functions.R")
#initial processing and merging of data#
allfiles = list.files("../raw_data/")
#initial processing and merging of data#
allfiles = list.files("../raw_data/")
sampdata=read_excel("../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx", sheet = 1)
library(Matrix)
library(Seurat)
library(dplyr)
library(readxl)
library(SeuratWrappers)
library(batchelor)
library(pheatmap)
library(patchwork)
library(ggplot2)
library(DropletUtils)
#initial processing and merging of data#
allfiles = list.files("../raw_data/")
sampdata=read_excel("../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx", sheet = 1)
featuredata = read_excel("../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx", sheet = 3)[-(1:2),]
View(featuredata)
featuredata = read_excel("../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx", sheet = 3)
featuredata = read_excel("../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx", sheet = 3)
featuredata$Name
#set up sample lists for aggregation#
allfiles_hash = allfiles[allfiles %in% featuredata$`Sequencing ID`]
allfiles_nohash = allfiles[!(allfiles %in% allfiles_hash)]
allfiles_hash
allfiles_nohash
#make full data objects#
dat_barcodes <- aggfilter_nonhash(allfiles_nohash, base_directory = "../raw_data/", umimin = 500, umimax = 10000, RP_filt = T, MT_filt = T)
alldat = dat_barcodes[[1]]; barcodes = dat_barcodes[[2]]
hash_counts <- aggfilter_hash(allfiles_hash, base_directory = "../raw_data/", umimin = 500, umimax = 10000,
HTO_filter = 0, feature_sheet = "../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx",
RP_filt = T, MT_filt = T)
feature_sheet = "../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx"
featuredata = read_excel(feature_sheet, sheet = 3)
H <- new.env(hash = T)
exists_hash <- Vectorize(exists, vectorize.args = "x")
for(i in 1:length(featuredata$Name)){
if(exists_hash(featuredata$Name[[i]], H)){
H[[featuredata$Name[[i]]]]= c(H[[featuredata$Name[[i]]]], paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = ""))
} else{
H[[featuredata$Name[[i]]]]= paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = "")
}
}
exists_hash(featuredata$Name[[i]], H)
?exists_hash
?exists_hash()
if(exists_hash(featuredata$Name[[i]], H))
featuredata
for(i in 1:length(featuredata$`Sequencing ID`)){
if(exists_hash(featuredata$`Sequencing ID`[[i]], H)){
H[[featuredata$`Sequencing ID`[[i]]]]= c(H[[featuredata$`Sequencing ID`[[i]]]], paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = ""))
} else{
H[[featuredata$`Sequencing ID`[[i]]]]= paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = "")
}
}
exists_hash
hash_counts <- aggfilter_hash(allfiles_hash, base_directory = "../raw_data/", umimin = 500, umimax = 10000,
HTO_filter = 0, feature_sheet = "../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx",
RP_filt = T, MT_filt = T)
source("clustering_diffex_functions.R")
hash_counts <- aggfilter_hash(allfiles_hash, base_directory = "../raw_data/", umimin = 500, umimax = 10000,
HTO_filter = 0, feature_sheet = "../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx",
RP_filt = T, MT_filt = T)
featuredata = read_excel(feature_sheet, sheet = 3)
H <- new.env(hash = T)
exists_hash <- Vectorize(exists, vectorize.args = "x")
for(i in 1:length(featuredata$`Sequencing ID`)){
if(exists_hash(featuredata$`Sequencing ID`[[i]], H)){
H[[featuredata$`Sequencing ID`[[i]]]]= c(H[[featuredata$`Sequencing ID`[[i]]]], paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = ""))
} else{
H[[featuredata$`Sequencing ID`[[i]]]]= paste("Hashtag", colnames(featuredata)[3:9][!is.na(featuredata[i, 3:9])], sep = "")
}
}
#create seurat objects for each separate sample#
seuratmat = list()
hashtag_frame = data.frame(Matrix(nrow = 0, ncol = 27))
allfiles_hash
i = 22
files = allfiles_hash
base_directory = "../raw_data/"; outdir = "../intermediate_data/demuxmix"
umimin = 500; umimax = 10000
HTO_filter = 0
RP_filt = F; MT_filt = T
tempname=paste(base_directory, files[i], "/", sep ="")
mmm=Read10X_h5(paste(tempname, "filtered_feature_bc_matrix.h5", sep = ""), use.names = T, unique.features = T)
hashmat=mmm[[2]]
cellmat=mmm[[1]]
joint.bcs <- intersect(colnames(cellmat), colnames(hashmat))
cellmat = cellmat[,joint.bcs]
hashmat = hashmat[,joint.bcs]
###mito filtering: choose the more $stringent$ of median or IQR filtering###
if(MT_filt == T){
mtpct=colSums(cellmat[grep("^MT-",rownames(cellmat)),])/colSums(cellmat)*100
med_cutoff = median(mtpct) + 2*mad(mtpct)
IQR_cutoff = as.numeric(quantile(mtpct)[4] + IQR(mtpct)*1.5)
mitofilter = min(med_cutoff, IQR_cutoff)
mitofilter = max(mitofilter, 10)
print(paste(files[i], " mito: med-", med_cutoff, ", IQR-", IQR_cutoff, sep = ""))
cellmat=cellmat[,which(mtpct<mitofilter)]  ###remove mito-heavy cells
hashmat=hashmat[,which(mtpct<mitofilter)]
}
i = 20
tempname=paste(base_directory, files[i], "/", sep ="")
mmm=Read10X_h5(paste(tempname, "filtered_feature_bc_matrix.h5", sep = ""), use.names = T, unique.features = T)
hashmat=mmm[[2]]
cellmat=mmm[[1]]
joint.bcs <- intersect(colnames(cellmat), colnames(hashmat))
cellmat = cellmat[,joint.bcs]
hashmat = hashmat[,joint.bcs]
###mito filtering: choose the more $stringent$ of median or IQR filtering###
if(MT_filt == T){
mtpct=colSums(cellmat[grep("^MT-",rownames(cellmat)),])/colSums(cellmat)*100
med_cutoff = median(mtpct) + 2*mad(mtpct)
IQR_cutoff = as.numeric(quantile(mtpct)[4] + IQR(mtpct)*1.5)
mitofilter = min(med_cutoff, IQR_cutoff)
mitofilter = max(mitofilter, 10)
print(paste(files[i], " mito: med-", med_cutoff, ", IQR-", IQR_cutoff, sep = ""))
cellmat=cellmat[,which(mtpct<mitofilter)]  ###remove mito-heavy cells
hashmat=hashmat[,which(mtpct<mitofilter)]
}
i
files
i = 21
tempname=paste(base_directory, files[i], "/", sep ="")
mmm=Read10X_h5(paste(tempname, "filtered_feature_bc_matrix.h5", sep = ""), use.names = T, unique.features = T)
hashmat=mmm[[2]]
cellmat=mmm[[1]]
joint.bcs <- intersect(colnames(cellmat), colnames(hashmat))
cellmat = cellmat[,joint.bcs]
hashmat = hashmat[,joint.bcs]
###mito filtering: choose the more $stringent$ of median or IQR filtering###
if(MT_filt == T){
mtpct=colSums(cellmat[grep("^MT-",rownames(cellmat)),])/colSums(cellmat)*100
med_cutoff = median(mtpct) + 2*mad(mtpct)
IQR_cutoff = as.numeric(quantile(mtpct)[4] + IQR(mtpct)*1.5)
mitofilter = min(med_cutoff, IQR_cutoff)
mitofilter = max(mitofilter, 10)
print(paste(files[i], " mito: med-", med_cutoff, ", IQR-", IQR_cutoff, sep = ""))
cellmat=cellmat[,which(mtpct<mitofilter)]  ###remove mito-heavy cells
hashmat=hashmat[,which(mtpct<mitofilter)]
}
###filter genes unlikely to be biologically relevant out, such as ribosomal/mitochondrial genes, then filter on UMI count##
if(RP_filt == T){
cellmat=cellmat[grep("^MT-|^RP[0-9]|^BC[0-9]|^RPL|^RPS|^MTRNR|-PS",rownames(cellmat),invert=T),] ###to remove all RP, MT, and pseudogenes
}else if (MT_filt == T){
cellmat=cellmat[grep("^MT-|^BC[0-9]|^MTRNR|-PS",rownames(cellmat),invert=T),] ###to remove MT + PS
} else{
cellmat=cellmat[grep("^BC[0-9]|-PS",rownames(cellmat),invert=T),] ###to remove MT + PS
}
#filter including those cells with no hashtag reads#
keepcells=which(colSums(cellmat) > umimin & colSums(cellmat) < umimax & colSums(hashmat) >= HTO_filter)
#retrieve the hashtag data and add it to a seurat object#
hashtag_frame = rbind(hashtag_frame, t(rowSums(hashmat[,keepcells])))
rownames(hashtag_frame)[dim(hashtag_frame)[1]] = files[i]
keephash = which(row.names(hashmat) %in% H[[files[i]]])
dat_seurat = CreateSeuratObject(counts=cellmat[,keepcells])
hashmat = hashmat[keephash,keepcells]
dat_seurat[["HTO"]]=CreateAssayObject(counts=hashmat)
hashmat
dim(hashmat)
length(hashmat)
H[[files[i]]]
source("clustering_diffex_functions.R")
hash_counts <- aggfilter_hash(allfiles_hash, base_directory = "../raw_data/", umimin = 500, umimax = 10000,
HTO_filter = 0, feature_sheet = "../intermediate_data/Table S1 - Overview of demographics, hashing strategy, and quality control, related to STAR Methods..xlsx",
RP_filt = T, MT_filt = T)
hash = merge(allhash[[1]], allhash[-1])
##Choose the manually curated labelling approach per dataset##
hash = SetIdent(object = hash, value = hash$Label)
hash = integrate_seurat_assignments(sample = "PM064", seurat = hash, other_tags = c("Hashtag7", "Hashtag8"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag9", "Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM066", seurat = hash, other_tags = c("Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag7", "Hashtag8"))
hash = integrate_seurat_assignments(sample = "PM078", seurat = hash, other_tags = c("Hashtag9", "Hashtag10"), alt_demux = "HTO_demux",
demuxMM_tags = c("Hashtag8"))
hash = integrate_seurat_assignments(sample = "PM080", seurat = hash, other_tags = c("Hashtag6", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM082", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM083", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM084", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = SetIdent(object = hash, value = hash$Label)
hash.subset <- subset(hash, idents = c("negative", "uncertain", "doublet"), invert = TRUE)
allhash = hash_counts[[1]]; counts = hash_counts[[2]]
hash = merge(allhash[[1]], allhash[-1])
##Choose the manually curated labelling approach per dataset##
hash = SetIdent(object = hash, value = hash$Label)
hash = integrate_seurat_assignments(sample = "PM064", seurat = hash, other_tags = c("Hashtag7", "Hashtag8"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag9", "Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM066", seurat = hash, other_tags = c("Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag7", "Hashtag8"))
hash = integrate_seurat_assignments(sample = "PM078", seurat = hash, other_tags = c("Hashtag9", "Hashtag10"), alt_demux = "HTO_demux",
demuxMM_tags = c("Hashtag8"))
hash = integrate_seurat_assignments(sample = "PM080", seurat = hash, other_tags = c("Hashtag6", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM082", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM083", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = integrate_seurat_assignments(sample = "PM084", seurat = hash, other_tags = c("Hashtag8", "Hashtag9"), alt_demux = "MULTI",
demuxMM_tags = c("Hashtag10"))
hash = SetIdent(object = hash, value = hash$Label)
hash.subset <- subset(hash, idents = c("negative", "uncertain", "doublet"), invert = TRUE)
dim(hash)
dim(hash.subset)
uglia.seurat = CreateSeuratObject(counts = alldat, min.cells = 3, names.delim = "-", names.field = 1, project = "uglia-complete")
if(!is.null(hash.subset)){
uglia.seurat = merge(uglia.seurat, hash.subset)
}
meta_params = c("Diagnosis (neurology)", "Brain region", "10x Chemistry Version", "Sex", "Age", "Donor ID")
meta = meta_params[1]
meta_col = rep(NA, length(Idents(uglia.seurat)))
unique(uglia.seurat$orig.ident)
sample = unique(uglia.seurat$orig.ident)[1]
samploc = grep(sample, sampdata$"Sequencing ID")
col = as.character(sampdata[samploc, meta])
col
meta
finalcol = grep(sample, uglia.seurat$orig.ident)
meta_col[finalcol] = col
uglia.seurat= AddMetaData(object = uglia.seurat, metadata = meta_col, col.name = meta)
names(meta_params) = c("diagnosis", "region", "tech", "sex", "age", "donor_ID")
meta = meta_params[1]
meta
meta_col = rep(NA, length(Idents(uglia.seurat)))
samploc = grep(sample, sampdata$"Sequencing ID")
col = as.character(sampdata[samploc, meta])
finalcol = grep(sample, uglia.seurat$orig.ident)
meta_col[finalcol] = col
meta_params[meta]
meta_params[metai = 1]
i = 1
meta_col = rep(NA, length(Idents(uglia.seurat)))
samploc = grep(sample, sampdata$"Sequencing ID")
col = as.character(sampdata[samploc, meta_params[i]])
finalcol = grep(sample, uglia.seurat$orig.ident)
meta_col[finalcol] = col
col
names(meta_params)[i]
meta_params = c("Diagnosis (neurology)", "Brain region", "10x Chemistry Version", "Sex", "Age", "Donor ID")
names(meta_params) = c("diagnosis", "region", "tech", "sex", "age", "donor_ID")
for(i in 1:length(meta_params)){
meta_col = rep(NA, length(Idents(uglia.seurat)))
for(sample in unique(uglia.seurat$orig.ident)){
samploc = grep(sample, sampdata$"Sequencing ID")
col = as.character(sampdata[samploc, meta_params[i]])
finalcol = grep(sample, uglia.seurat$orig.ident)
meta_col[finalcol] = col
}
uglia.seurat= AddMetaData(object = uglia.seurat, metadata = meta_col, col.name = names(meta_params)[i])
}
uglia.seurat$diagnosis
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
#generate the combined seurat object with added metadata and finalized hash assignments#
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
#generate the combined seurat object with added metadata and finalized hash assignments#
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
#generate the combined seurat object with added metadata and finalized hash assignments#
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
#generate the combined seurat object with added metadata and finalized hash assignments#
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
#generate the combined seurat object with added metadata and finalized hash assignments#
uglia.seurat <- makeseurat_metadata(alldat = alldat, allhash = allhash, sampdata = sampdata, featuredata = featuredata)
#using top-level cluster assignments, perform subclustering of microglia#
assigned_idents = read.csv("../intermediate_data/4.5k40_batch_SCTv3_0.5_idents.csv")
names = assigned_idents[,1]
assigned_idents = data.frame(assigned_idents[,2])
row.names(assigned_idents) = names
uglia.seurat = AddMetaData(object = uglia.seurat, metadata = assigned_idents, col.name = "assigned_idents")
uglia.seurat = SetIdent(object = uglia.seurat, value = uglia.seurat$assigned_idents)
##get uglia
uglia_only = subset(uglia.seurat, idents = c(0:8, 10:13, 15))
dim(uglia_only)
View(assigned_idents)
#using top-level cluster assignments, perform subclustering of microglia#
assigned_idents = read.csv("../intermediate_data/4.5k40_batch_SCTv3_0.5_idents.csv")
#using top-level cluster assignments, perform subclustering of microglia#
assigned_idents = read.csv("../intermediate_data/4.5k40_batch_SCTv3_0.5_idents.csv")
names = assigned_idents[,1]
assigned_idents = data.frame(assigned_idents[,2])
row.names(assigned_idents) = names
uglia.seurat = AddMetaData(object = uglia.seurat, metadata = assigned_idents, col.name = "assigned_idents")
uglia.seurat = SetIdent(object = uglia.seurat, value = uglia.seurat$assigned_idents)
##get microglia
uglia_only = subset(uglia.seurat, idents = c(0:8, 10:13, 15))
dim(uglia_only)
View(assigned_idents)
names(uglia.seurat)
rownames(uglia.seurat)
colnames(uglia.seurat)
unique(uglia.seurat$orig.ident)
#using top-level cluster assignments, perform subclustering of microglia#
assigned_idents = read.csv("../intermediate_data/4.5k40_batch_SCTv3_0.5_idents.csv")
names = assigned_idents[,1]
assigned_idents = data.frame(assigned_idents[,2])
row.names(assigned_idents) = names
uglia.seurat = AddMetaData(object = uglia.seurat, metadata = assigned_idents, col.name = "assigned_idents")
uglia.seurat = SetIdent(object = uglia.seurat, value = uglia.seurat$assigned_idents)
##get microglia
uglia_only = subset(uglia.seurat, idents = c(0:8, 10:13, 15))
dim(uglia_only)
dim(uglia.seurat)
table(assigned_idents$assigned_idents...2.)
34970+33860+32579+27237+22208+20113+15012+8932+6226+4327+3552+2807+2443+1414
Idents(uglia.seurat)
table(Idents(uglia.seurat))
table(assigned_idents$assigned_idents...2.)
tmp = uglia.seurat@meta.data
View(tmp)
allfiles
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
source("~/GitHub/single-cell-microglia-v2/Preprocessing and Clustering/clustering_diffex_functions.R")
